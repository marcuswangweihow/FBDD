{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58963feb-5440-4f53-939a-e1d1b3054d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd6884-74de-4901-9658-e91e34f52f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038bae8a-52e2-422f-9afc-e2b533129f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1423f-f980-4a05-a607-4dd8d54e073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d80f5-db7f-4e55-8f5e-3d54a26264f4",
   "metadata": {},
   "source": [
    "# Function for calculating descriptors using rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23eafa2b-626c-494a-a995-e35e4146b591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T08:47:52.700298Z",
     "iopub.status.busy": "2025-11-04T08:47:52.700298Z",
     "iopub.status.idle": "2025-11-04T08:47:52.704623Z",
     "shell.execute_reply": "2025-11-04T08:47:52.704623Z",
     "shell.execute_reply.started": "2025-11-04T08:47:52.700298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_descriptors function initialized\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# This calculates relevant descriptors for each molecule in a list\n",
    "# This returns a list of descriptors for each molecule\n",
    "# to convert the list to a df just do df = pd.DataFrame(data)\n",
    "def get_descriptors(mol_list):\n",
    "    data = []\n",
    "    for mol in mol_list:\n",
    "        desc = {\n",
    "            'MolWt': Descriptors.MolWt(mol),\n",
    "            'MolLogP': Descriptors.MolLogP(mol),\n",
    "            'TPSA': Descriptors.TPSA(mol),\n",
    "            'NumHDonors': Descriptors.NumHDonors(mol),\n",
    "            'NumHAcceptors': Descriptors.NumHAcceptors(mol)\n",
    "        }\n",
    "        data.append(desc)\n",
    "\n",
    "    return data\n",
    "    \n",
    "print('get_descriptors function initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d2507-602b-4129-b7c0-b11752ccac84",
   "metadata": {},
   "source": [
    "# Function for taking a dataframe as input and using it to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "586426c3-bbd7-4e47-978f-ae47e47f5ab5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T08:48:08.962214Z",
     "iopub.status.busy": "2025-11-04T08:48:08.962214Z",
     "iopub.status.idle": "2025-11-04T08:48:09.604934Z",
     "shell.execute_reply": "2025-11-04T08:48:09.604934Z",
     "shell.execute_reply.started": "2025-11-04T08:48:08.962214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fragment_model function initialized\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Train a neural network using molecular descriptors to predict labels eg.\n",
    "ligand efficiency or fragment hit probability.\n",
    "\n",
    "Input is a pandas dataframe\n",
    "\"\"\"\n",
    "\n",
    "def train_fragment_model(df, target_col=\"target\", epochs=50, batch_size=16, lr=1e-3, hidden_dim=128, test_split=0.2):\n",
    "\n",
    "    # Split features and target\n",
    "    X = df.drop(columns=[target_col]).values.astype(np.float32)\n",
    "    y = df[target_col].values.astype(np.float32)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_tensor = torch.tensor(X)\n",
    "    y_tensor = torch.tensor(y).view(-1, 1)\n",
    "\n",
    "    # Train/test split\n",
    "    n_total = len(df)\n",
    "    n_test = int(n_total * test_split)\n",
    "    n_train = n_total - n_test\n",
    "    \n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    train_ds, test_ds = random_split(dataset, [n_train, n_test])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # Model definition\n",
    "    input_dim = X.shape[1] # Width of layers\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_dim, hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, hidden_dim//2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim//2, hidden_dim//4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim//4, 1),\n",
    "\n",
    "        # Remove if for regression task\n",
    "        nn.Sigmoid()  \n",
    "    )\n",
    "\n",
    "    # Set criterion depending on expected output eg. for classification or regression\n",
    "    # For regression use MSELoss\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # As usual Adam is used\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Get test data as tensors\n",
    "    X_test, y_test = next(iter(DataLoader(test_ds, batch_size=len(test_ds))))\n",
    "    \n",
    "    return model, (X_test, y_test)\n",
    "\n",
    "print('train_fragment_model function initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982aedd-456f-4ba4-9de9-c5b5451d6f8b",
   "metadata": {},
   "source": [
    "# Function to define evaluation metrics to evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ab29a87-10ad-4ecb-bbf3-b999608974dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T08:48:24.708608Z",
     "iopub.status.busy": "2025-11-04T08:48:24.708608Z",
     "iopub.status.idle": "2025-11-04T08:48:24.742443Z",
     "shell.execute_reply": "2025-11-04T08:48:24.742443Z",
     "shell.execute_reply.started": "2025-11-04T08:48:24.708608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_model function initialized\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, threshold=0.5):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probs = model(X_test).numpy().flatten()\n",
    "        \n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    y_true = y_test.numpy().flatten().astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Sensitivity (Recall): {sensitivity:.3f}\")\n",
    "    print(f\"Specificity: {specificity:.3f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    eval_metrics = {\"accuracy\": accuracy,\n",
    "                    \"sensitivity\": sensitivity,\n",
    "                    \"specificity\": specificity,\n",
    "                    \"confusion_matrix\": cm\n",
    "                   }\n",
    "    \n",
    "\n",
    "    return eval_metrics\n",
    "\n",
    "print('evaluate_model function initialized')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d631619-d0ae-4395-8602-72f0579a3678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
